{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint20 セグメンテーション２"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:39.259864Z",
     "start_time": "2020-03-25T14:39:39.039884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:43.879310Z",
     "start_time": "2020-03-25T14:39:43.876304Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:44.446808Z",
     "start_time": "2020-03-25T14:39:44.431975Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:47.676622Z",
     "start_time": "2020-03-25T14:39:47.485724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./Kaggle/TGS-Salt/train.csv')\n",
    "test = pd.read_csv('./Kaggle/TGS-Salt/sample_submission.csv')\n",
    "depth = pd.read_csv('./Kaggle/TGS-Salt/depths.csv')\n",
    "\n",
    "train_src = './Kaggle/TGS-Salt/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:58.581787Z",
     "start_time": "2020-03-25T14:39:50.781893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./Kaggle/TGS-Salt/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./Kaggle/TGS-Salt/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:59.083122Z",
     "start_time": "2020-03-25T14:39:58.584544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8598eff8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:08.034054Z",
     "start_time": "2020-03-25T14:40:07.987000Z"
    }
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.924796Z",
     "start_time": "2020-03-25T14:40:09.595933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337, shuffle=True)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.952868Z",
     "start_time": "2020-03-25T14:40:35.927679Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:43.034360Z",
     "start_time": "2020-03-25T14:40:35.954603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "input_size = (224, 224, 3)\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:46.197121Z",
     "start_time": "2020-03-25T14:40:46.188335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:54:51.684488Z",
     "start_time": "2020-03-25T14:54:51.673231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    # 学習しないlayerは、trainable = False\n",
    "    for layer in model.layers[:172]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:55:00.601042Z",
     "start_time": "2020-03-25T14:54:53.772115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,970,161\n",
      "Trainable params: 25,385,361\n",
      "Non-trainable params: 23,584,800\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "K.clear_session()\n",
    "model_resnet = unet_resnet(\n",
    "    input_size,\n",
    "    decoder_block_bottleneck,\n",
    "    weights='imagenet',\n",
    "    loss_func=bce_dice_loss,\n",
    "    metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_resnet.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Trainable =====\n",
      "input_1                False\n",
      "conv1_pad              False\n",
      "conv1                  False\n",
      "bn_conv1               False\n",
      "activation_1           False\n",
      "pool1_pad              False\n",
      "max_pooling2d_1        False\n",
      "res2a_branch2a         False\n",
      "bn2a_branch2a          False\n",
      "activation_2           False\n",
      "res2a_branch2b         False\n",
      "bn2a_branch2b          False\n",
      "activation_3           False\n",
      "res2a_branch2c         False\n",
      "res2a_branch1          False\n",
      "bn2a_branch2c          False\n",
      "bn2a_branch1           False\n",
      "add_1                  False\n",
      "activation_4           False\n",
      "res2b_branch2a         False\n",
      "bn2b_branch2a          False\n",
      "activation_5           False\n",
      "res2b_branch2b         False\n",
      "bn2b_branch2b          False\n",
      "activation_6           False\n",
      "res2b_branch2c         False\n",
      "bn2b_branch2c          False\n",
      "add_2                  False\n",
      "activation_7           False\n",
      "res2c_branch2a         False\n",
      "bn2c_branch2a          False\n",
      "activation_8           False\n",
      "res2c_branch2b         False\n",
      "bn2c_branch2b          False\n",
      "activation_9           False\n",
      "res2c_branch2c         False\n",
      "bn2c_branch2c          False\n",
      "add_3                  False\n",
      "activation_10          False\n",
      "res3a_branch2a         False\n",
      "bn3a_branch2a          False\n",
      "activation_11          False\n",
      "res3a_branch2b         False\n",
      "bn3a_branch2b          False\n",
      "activation_12          False\n",
      "res3a_branch2c         False\n",
      "res3a_branch1          False\n",
      "bn3a_branch2c          False\n",
      "bn3a_branch1           False\n",
      "add_4                  False\n",
      "activation_13          False\n",
      "res3b_branch2a         False\n",
      "bn3b_branch2a          False\n",
      "activation_14          False\n",
      "res3b_branch2b         False\n",
      "bn3b_branch2b          False\n",
      "activation_15          False\n",
      "res3b_branch2c         False\n",
      "bn3b_branch2c          False\n",
      "add_5                  False\n",
      "activation_16          False\n",
      "res3c_branch2a         False\n",
      "bn3c_branch2a          False\n",
      "activation_17          False\n",
      "res3c_branch2b         False\n",
      "bn3c_branch2b          False\n",
      "activation_18          False\n",
      "res3c_branch2c         False\n",
      "bn3c_branch2c          False\n",
      "add_6                  False\n",
      "activation_19          False\n",
      "res3d_branch2a         False\n",
      "bn3d_branch2a          False\n",
      "activation_20          False\n",
      "res3d_branch2b         False\n",
      "bn3d_branch2b          False\n",
      "activation_21          False\n",
      "res3d_branch2c         False\n",
      "bn3d_branch2c          False\n",
      "add_7                  False\n",
      "activation_22          False\n",
      "res4a_branch2a         False\n",
      "bn4a_branch2a          False\n",
      "activation_23          False\n",
      "res4a_branch2b         False\n",
      "bn4a_branch2b          False\n",
      "activation_24          False\n",
      "res4a_branch2c         False\n",
      "res4a_branch1          False\n",
      "bn4a_branch2c          False\n",
      "bn4a_branch1           False\n",
      "add_8                  False\n",
      "activation_25          False\n",
      "res4b_branch2a         False\n",
      "bn4b_branch2a          False\n",
      "activation_26          False\n",
      "res4b_branch2b         False\n",
      "bn4b_branch2b          False\n",
      "activation_27          False\n",
      "res4b_branch2c         False\n",
      "bn4b_branch2c          False\n",
      "add_9                  False\n",
      "activation_28          False\n",
      "res4c_branch2a         False\n",
      "bn4c_branch2a          False\n",
      "activation_29          False\n",
      "res4c_branch2b         False\n",
      "bn4c_branch2b          False\n",
      "activation_30          False\n",
      "res4c_branch2c         False\n",
      "bn4c_branch2c          False\n",
      "add_10                 False\n",
      "activation_31          False\n",
      "res4d_branch2a         False\n",
      "bn4d_branch2a          False\n",
      "activation_32          False\n",
      "res4d_branch2b         False\n",
      "bn4d_branch2b          False\n",
      "activation_33          False\n",
      "res4d_branch2c         False\n",
      "bn4d_branch2c          False\n",
      "add_11                 False\n",
      "activation_34          False\n",
      "res4e_branch2a         False\n",
      "bn4e_branch2a          False\n",
      "activation_35          False\n",
      "res4e_branch2b         False\n",
      "bn4e_branch2b          False\n",
      "activation_36          False\n",
      "res4e_branch2c         False\n",
      "bn4e_branch2c          False\n",
      "add_12                 False\n",
      "activation_37          False\n",
      "res4f_branch2a         False\n",
      "bn4f_branch2a          False\n",
      "activation_38          False\n",
      "res4f_branch2b         False\n",
      "bn4f_branch2b          False\n",
      "activation_39          False\n",
      "res4f_branch2c         False\n",
      "bn4f_branch2c          False\n",
      "add_13                 False\n",
      "activation_40          False\n",
      "res5a_branch2a         False\n",
      "bn5a_branch2a          False\n",
      "activation_41          False\n",
      "res5a_branch2b         False\n",
      "bn5a_branch2b          False\n",
      "activation_42          False\n",
      "res5a_branch2c         False\n",
      "res5a_branch1          False\n",
      "bn5a_branch2c          False\n",
      "bn5a_branch1           False\n",
      "add_14                 False\n",
      "activation_43          False\n",
      "res5b_branch2a         False\n",
      "bn5b_branch2a          False\n",
      "activation_44          False\n",
      "res5b_branch2b         False\n",
      "bn5b_branch2b          False\n",
      "activation_45          False\n",
      "res5b_branch2c         False\n",
      "bn5b_branch2c          False\n",
      "add_15                 False\n",
      "activation_46          False\n",
      "res5c_branch2a         False\n",
      "bn5c_branch2a          False\n",
      "activation_47          False\n",
      "res5c_branch2b         False\n",
      "bn5c_branch2b          False\n",
      "activation_48          False\n",
      "res5c_branch2c         False\n",
      "center_conv1           True\n",
      "center_bn1             True\n",
      "center_activation1     True\n",
      "dropout_1              True\n",
      "center_conv2           True\n",
      "center_bn2             True\n",
      "center_activation2     True\n",
      "dropout_2              True\n",
      "center_conv3           True\n",
      "center_bn3             True\n",
      "center_activation3     True\n",
      "dropout_3              True\n",
      "add_17                 True\n",
      "concatenate_1          True\n",
      "decoder4_conv1         True\n",
      "decoder4_bn1           True\n",
      "decoder4_activation1   True\n",
      "dropout_4              True\n",
      "decoder4_conv2         True\n",
      "decoder4_bn2           True\n",
      "decoder4_activation2   True\n",
      "dropout_5              True\n",
      "decoder4_conv3         True\n",
      "decoder4_bn3           True\n",
      "decoder4_activation3   True\n",
      "dropout_6              True\n",
      "add_18                 True\n",
      "up_sampling2d_1        True\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Trainable =====\")\n",
    "for layer in model_resnet.layers[:200]:\n",
    "    print(\"{}   {}\".format(str(layer.name).ljust(20), layer.trainable))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T17:37:03.773696Z",
     "start_time": "2020-03-25T14:58:43.483800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/koyamasatoshi/.pyenv/versions/anaconda3-2019.10/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/3\n",
      "3200/3200 [==============================] - 2619s 819ms/step - loss: 0.6884 - my_iou_metric: 0.3268 - val_loss: 6.3863 - val_my_iou_metric: 0.1271\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.12713, saving model to unet_resnet.h5\n",
      "Epoch 2/3\n",
      "3200/3200 [==============================] - 2621s 819ms/step - loss: 0.5394 - my_iou_metric: 0.4235 - val_loss: 1.7963 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.12713\n",
      "Epoch 3/3\n",
      "3200/3200 [==============================] - 2579s 806ms/step - loss: 0.4716 - my_iou_metric: 0.4799 - val_loss: 4.1553 - val_my_iou_metric: 0.1327\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.12713 to 0.13275, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "epochs = 3  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_resnet.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    validation_data=[X_val, y_val], \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[model_checkpoint,reduce_lr], \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_resnet.predict(X_val, batch_size=16)\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:29<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5245 at threshold: 0.800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.523796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.519500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.524063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.524500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.523796\n",
       "std     0.204939   0.000942\n",
       "min     0.200000   0.519500\n",
       "25%     0.370000   0.524000\n",
       "50%     0.540000   0.524000\n",
       "75%     0.710000   0.524063\n",
       "max     0.880000   0.524500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f849410d610>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題１】コードレビュー  \n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。  \n",
    "\n",
    "- 前回使用した実装とはどのように違うのか  \n",
    "前回はU-Netのみ。今回はUNetのencoder部分をbase_model（ResNet）から持ってきて代入している。\n",
    "\n",
    "```python\n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "```\n",
    "\n",
    "\n",
    "- 転移学習をどのように行っているか  \n",
    "重みをImageNetで学習済みのものを使用している。  \n",
    "\n",
    "```python  \n",
    "model_resnet = unet_resnet(input_size,\n",
    "                          decoder_block_bottleneck,\n",
    "                          weights='imagenet',\n",
    "                          loss_func=bce_dice_loss,\n",
    "                          metrics_list=[my_iou_metric],\n",
    "                          use_lovash=False)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題２】コードの書き換え  \n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGを使う。\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder - VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks - VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(layer_name, block_name, num_filters=32, conv_dim=(3, 3)):\n",
    "    x_dec = Conv2D(num_filters, conv_dim, padding='same', name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(name='{}_activation'.format(block_name))(x_dec)\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(layer_name, block_name, num_filters=32, conv_dim=(3, 3), dropout_frac=0.2):\n",
    "    x_dec = Conv2D(num_filters, conv_dim, padding='same', name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(num_filters // 2, conv_dim, padding='same', name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(num_filters, conv_dim, padding='same', name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition - UNet-VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg(input_size, decoder_block, weights='imagenet', loss_func='binary_crossentropy', metrics_list=[my_iou_metric], use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(input_shape=input_size, include_top=False, weights=weights)\n",
    "    \n",
    "    # Encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output  # 64\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output  # 128\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output  # 256\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output  # 512\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output  # 512\n",
    "\n",
    "    # Center block\n",
    "    encoder6 = base_model.get_layer('block5_pool').output\n",
    "    center = decoder_block(encoder6, 'center', num_filters=512)\n",
    "    concat6 = concatenate([center, encoder6], axis=-1)\n",
    "\n",
    "    # Decoder part\n",
    "    decoder5 = decoder_block(concat6, 'decoder5', num_filters=512)\n",
    "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1)\n",
    "\n",
    "    decoder4 = decoder_block(concat5, 'decoder4', num_filters=512)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "    \n",
    "    decoder3 = decoder_block(concat4, 'decoder3', num_filters=256)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(concat3, 'decoder2', num_filters=128)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(concat2, 'decoder1', num_filters=64)\n",
    "    output = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final decoder block for segmentation.\n",
    "    # output = decoder_block(output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    # 転移学習のlayerは、trainable = False\n",
    "    for layer in model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題３】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model - UNet-VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv1 (Conv2D)         (None, 7, 7, 512)    4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation1 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv2 (Conv2D)         (None, 7, 7, 256)    1179904     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn2 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation2 (PReLU)    (None, 7, 7, 256)    12544       decoder5_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 256)    0           decoder5_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv3 (Conv2D)         (None, 7, 7, 512)    1180160     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn3 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation3 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 512)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 512)  4719104     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 256)  1179904     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 512)  1180160     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 512)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 256)  2359552     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 128)  295040      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 128)  0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 256)  295168      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 256)  0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 128)  589952      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 64)   73792       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 128)  73856       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 128)  0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 147520      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 112, 112, 64) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  129         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 41,373,345\n",
      "Trainable params: 26,648,737\n",
      "Non-trainable params: 14,724,608\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model_vgg = unet_vgg(input_size, decoder_block_bottleneck, weights='imagenet', loss_func=bce_dice_loss, metrics_list=[my_iou_metric], use_lovash=False)\n",
    "print(model_vgg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Trainable Layers =====\n",
      "input_1               False\n",
      "block1_conv1          False\n",
      "block1_conv2          False\n",
      "block1_pool           False\n",
      "block2_conv1          False\n",
      "block2_conv2          False\n",
      "block2_pool           False\n",
      "block3_conv1          False\n",
      "block3_conv2          False\n",
      "block3_conv3          False\n",
      "block3_pool           False\n",
      "block4_conv1          False\n",
      "block4_conv2          False\n",
      "block4_conv3          False\n",
      "block4_pool           False\n",
      "block5_conv1          False\n",
      "block5_conv2          False\n",
      "block5_conv3          False\n",
      "block5_pool           False\n",
      "center_conv1          True\n",
      "center_bn1            True\n",
      "center_activation1    True\n",
      "dropout_1             True\n",
      "center_conv2          True\n",
      "center_bn2            True\n",
      "center_activation2    True\n",
      "dropout_2             True\n",
      "center_conv3          True\n",
      "center_bn3            True\n",
      "center_activation3    True\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# 学習するかどうか\n",
    "print(\"===== Trainable Layers =====\")\n",
    "for layer in model_vgg.layers[:30]:\n",
    "    print(\"{}  {}\".format(str(layer.name).ljust(20), layer.trainable))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/3\n",
      "3200/3200 [==============================] - 3546s 1s/step - loss: 0.8560 - my_iou_metric: 0.2420 - val_loss: 1.5405 - val_my_iou_metric: 0.1905\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.19050, saving model to unet_vgg16.h5\n",
      "Epoch 2/3\n",
      "3200/3200 [==============================] - 3547s 1s/step - loss: 0.6155 - my_iou_metric: 0.3656 - val_loss: 0.8934 - val_my_iou_metric: 0.3958\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.19050 to 0.39575, saving model to unet_vgg16.h5\n",
      "Epoch 3/3\n",
      "3200/3200 [==============================] - 3530s 1s/step - loss: 0.5460 - my_iou_metric: 0.4212 - val_loss: 0.5364 - val_my_iou_metric: 0.5290\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.39575 to 0.52900, saving model to unet_vgg16.h5\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg.h5',\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1)\n",
    "\n",
    "epochs = 3  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_vgg.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_vgg.predict(X_val, batch_size=16)\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:34<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5851 at threshold: 0.760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.559132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.024919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.489875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.547750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.570125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.578313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.585125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.559132\n",
       "std     0.204939   0.024919\n",
       "min     0.200000   0.489875\n",
       "25%     0.370000   0.547750\n",
       "50%     0.540000   0.570125\n",
       "75%     0.710000   0.578313\n",
       "max     0.880000   0.585125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8488742e10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較\n",
    "- IoU  \n",
    "学習は十分ではないが、3 epochsの学習で比較すると、Best IoUはVGGの方が良かった。  \n",
    "またVGGでは、閾値が0や1に近い場合にIoUが減少する結果になったが、  \n",
    "ResNetでは、閾値を変化させても、IoUはほぼ一定であった。  \n",
    "\n",
    "__ResNet__: Best IoU: 0.5245 at threshold: 0.800  \n",
    "__VGG16__ : Best IoU: 0.5851 at threshold: 0.760\n",
    "\n",
    "- 実行時間  \n",
    "VGGの方が実行時間は長かった。  \n",
    "\n",
    "__UNet-ResNet__: およそ2600s/epoch (43min/epoch)   \n",
    "__UNet-VGG16__ : およそ3500s/epoch (58min/epoch)  \n",
    "\n",
    "- パラメータ数  \n",
    "Totalパラメータ数はResNetの方が多いが、転移学習時に学習させるパラメータ数はVGG16の方が多かった。  \n",
    "    - __UNet-ResNet__  \n",
    "    Total params: 48,970,161  \n",
    "    Trainable params: 25,385,361  \n",
    "    Non-trainable params: 23,584,800  \n",
    "\n",
    "    - __UNet-VGG16__  \n",
    "    Total params: 41,373,345  \n",
    "    Trainable params: 26,648,737  \n",
    "    Non-trainable params: 14,724,608  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
